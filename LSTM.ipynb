{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# check if GPU is available (better to check it at the start)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "10n3gVIf3EhI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147cd879-b70e-4af3-fb4a-7e8f7f14139e"
      },
      "id": "10n3gVIf3EhI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: True \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c909b93e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b63aea-3779-43a8-9d85-051924884e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'Video_Games.json.gz' downloaded successfully.\n",
            "497577\n",
            "{'overall': 5.0, 'verified': True, 'reviewTime': '10 17, 2015', 'reviewerID': 'A1HP7NVNPFMA4N', 'asin': '0700026657', 'reviewerName': 'Ambrosia075', 'reviewText': \"This game is a bit hard to get the hang of, but when you do it's great.\", 'summary': \"but when you do it's great.\", 'unixReviewTime': 1445040000}\n"
          ]
        }
      ],
      "source": [
        "# download via API/Internet\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "from urllib.request import urlopen\n",
        "\n",
        "# data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# download the data from link\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# URL of the file you want to download\n",
        "url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Video_Games_5.json.gz\"\n",
        "\n",
        "# Local path where you want to save the downloaded file\n",
        "local_filename = \"Video_Games.json.gz\"\n",
        "\n",
        "# Check if the file already exists, if yes, remove it\n",
        "if os.path.exists(local_filename):\n",
        "    os.remove(local_filename)\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "with open(local_filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "print(f\"File '{local_filename}' downloaded successfully.\")\n",
        "\n",
        "# load the meta data\n",
        "data = []\n",
        "with gzip.open(local_filename, 'rt') as f:  # 'rt' for text mode\n",
        "    for l in f:\n",
        "        data.append(json.loads(l.strip()))\n",
        "\n",
        "# total length of the list, this number equals the total number of products\n",
        "print(len(data))\n",
        "\n",
        "# first row of the list\n",
        "print(data[0])\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('Video_Games.json.gz')\n",
        "df=df[:100000]"
      ],
      "id": "c909b93e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aca77d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cb6e15-cc2c-4684-ef85-028477f62ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of DataFrame: 100000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of DataFrame: {len(df)}\")"
      ],
      "id": "aca77d58"
    },
    {
      "cell_type": "code",
      "source": [
        "# fill blank spaces with NaN\n",
        "df = df.fillna('')\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl2oSZEOENAy",
        "outputId": "0f1c4852-9985-4052-cddc-c5b7d48d76e0"
      },
      "id": "Kl2oSZEOENAy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "overall           0\n",
              "verified          0\n",
              "reviewTime        0\n",
              "reviewerID        0\n",
              "asin              0\n",
              "reviewerName      0\n",
              "reviewText        0\n",
              "summary           0\n",
              "unixReviewTime    0\n",
              "vote              0\n",
              "style             0\n",
              "image             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower case all reviews, ensuring that each entry is a string\n",
        "df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: str(x).lower())\n",
        "\n",
        "# Get rid of punctuation and newline\n",
        "df[\"reviewText\"] = df[\"reviewText\"].str.replace(r'[^\\w\\s]+', '', regex=True).str.replace(\"\\n\", \" \")\n"
      ],
      "metadata": {
        "id": "js_kG43EEsP5"
      },
      "id": "js_kG43EEsP5",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_relevant_rev = [\"verified\",  \"vote\", \"style\", \"image\", \"unixReviewTime\"]\n",
        "df = df.drop(non_relevant_rev, axis = 1)"
      ],
      "metadata": {
        "id": "sX71HS9CFX70"
      },
      "id": "sX71HS9CFX70",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d19fed12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f849853f-0512-4e37-df3b-f5174505c3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99946\n"
          ]
        }
      ],
      "source": [
        "# data clean\n",
        "# 1. Removing duplicates\n",
        "df = df.drop_duplicates()\n",
        "print(len(df))"
      ],
      "id": "d19fed12"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0c53f4aa"
      },
      "outputs": [],
      "source": [
        "# 2. Handling missing values\n",
        "df.fillna(0, inplace=True) # Replace 0 with your desired placeholde"
      ],
      "id": "0c53f4aa"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "528b1783"
      },
      "outputs": [],
      "source": [
        "#3. Converting data types\n",
        "df['reviewTime'] = pd.to_datetime(df['reviewTime'], errors='coerce')"
      ],
      "id": "528b1783"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ff1d3861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c626b85-d1c7-444e-dcc9-f0e27ee079db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " overall         0\n",
            "reviewTime      0\n",
            "reviewerID      0\n",
            "asin            0\n",
            "reviewerName    0\n",
            "reviewText      0\n",
            "summary         0\n",
            "dtype: int64\n",
            "Summary statistics:\n",
            "             overall\n",
            "count  99946.000000\n",
            "mean       4.208983\n",
            "std        1.138513\n",
            "min        1.000000\n",
            "25%        4.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print('Missing values:\\n', df.isnull().sum())\n",
        "# Print summary statistics\n",
        "print('Summary statistics:\\n', df.describe())"
      ],
      "id": "ff1d3861"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b4e1fc89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2931df98-70b4-4a17-e70c-26ab6ca7341c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 4., 3., 2., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "unique_overallrating_values = df['overall'].unique()\n",
        "unique_overallrating_values"
      ],
      "id": "b4e1fc89"
    },
    {
      "cell_type": "code",
      "source": [
        " # Rename the DataFrame\n",
        "clean_data = df.copy()\n",
        "\n",
        "clean_data.to_csv('clean_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "msFEqp7bMeM4"
      },
      "id": "msFEqp7bMeM4",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fbeb90a3"
      },
      "outputs": [],
      "source": [
        "# Create a new DataFrame 'reviews' and 'labels'\n",
        "reviews = pd.DataFrame()\n",
        "labels = pd.DataFrame()\n",
        "# Map sentiment values based on 'overall' column\n",
        "labels['labels'] = df['overall'].map({1: 'negative', 2: 'negative', 3: 'neutral', 4: 'positive', 5: 'positive'})\n",
        "\n",
        "# Assign 'review' column from the original DataFrame 'df'\n",
        "reviews['review'] = df['reviewText']"
      ],
      "id": "fbeb90a3"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c906abe5"
      },
      "outputs": [],
      "source": [
        "path_file_path = \"/content/\"\n",
        "\n",
        "# Save the 'reviews' DataFrame to a text file\n",
        "reviews.to_csv(path_file_path + \"reviews.txt\", index=False)\n",
        "\n",
        "# Save the 'labels' DataFrame to a text file\n",
        "labels.to_csv(path_file_path + \"labels.txt\", index=False)"
      ],
      "id": "c906abe5"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FHRdLhTPyL27"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# read data from text files\n",
        "with open('reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "id": "FHRdLhTPyL27"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "97d013d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4d71f4-0fc4-4ade-ef36-9784930182ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review\n",
            "this game is a bit hard to get the hang of but when you do its great\n",
            "i played it a while but it was alright the steam was a bit of trouble the more they move these game to steam the more of a hard time i have activating and playing a game but in spite of that it was fun i liked it now i am looking forward to anno 2205 i really want to play my way to the moon\n",
            "ok game\n",
            "found the game a bit too complicated not what i expected after having played 1602 1503 and 1701\n",
            "great game i love it and have played it since its arrived\n",
            "i liked a lot some time that i havent play a wonderfull game very simply and funny game verry good game\n",
            "im an avid gamer but anno 2070 is an insult to gaming  it is so buggy and halffinished that the first campaign doesnt even work properly and the drm is incredibly frustrating to deal with  once you manage to work your way past the massive amounts of bugs and get through the drm hours later you finally figure out that the game has no real tutorial so you stuck just\n",
            "\n",
            "labels\n",
            "positive\n",
            "posi\n"
          ]
        }
      ],
      "source": [
        "print(reviews[:1000])\n",
        "print()\n",
        "print(labels[:20])"
      ],
      "id": "97d013d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOvV10qqyUei"
      },
      "source": [
        "# Data pre-processing"
      ],
      "id": "SOvV10qqyUei"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3188aea7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b43f54f-372f-43aa-86fb-7f14b487ccf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "# Data pre-processing\n",
        "from string import punctuation\n",
        "\n",
        "print(punctuation)\n",
        "\n",
        "# get rid of punctuation\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()"
      ],
      "id": "3188aea7"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8d00d0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2ca040-0a60-4f37-cdc4-1398b761ff4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['review',\n",
              " 'this',\n",
              " 'game',\n",
              " 'is',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'hard',\n",
              " 'to',\n",
              " 'get',\n",
              " 'the',\n",
              " 'hang',\n",
              " 'of',\n",
              " 'but',\n",
              " 'when',\n",
              " 'you',\n",
              " 'do',\n",
              " 'its',\n",
              " 'great',\n",
              " 'i',\n",
              " 'played',\n",
              " 'it',\n",
              " 'a',\n",
              " 'while',\n",
              " 'but',\n",
              " 'it',\n",
              " 'was',\n",
              " 'alright',\n",
              " 'the',\n",
              " 'steam',\n",
              " 'was']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "words[:30]"
      ],
      "id": "8d00d0c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-pP9J1lyXUA"
      },
      "source": [
        "Encoding the words"
      ],
      "id": "T-pP9J1lyXUA"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "632bc9e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import Counter\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "\n",
        "#Build a dictionary that maps words to integers by enumerating vocab\n",
        "vocab_to_int = {word: index + 1 for index, word in enumerate(vocab)}\n",
        "\n",
        "## store the tokenized reviews in reviews_ints (which is a list)\n",
        "reviews_ints = []\n",
        "for review in reviews_split:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
      ],
      "id": "632bc9e6"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5ayX4WxDyXk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49213071-1abf-4952-f7f6-8ef00523ed5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words:  182030\n",
            "\n",
            "Tokenized review: \n",
            " [[354]]\n"
          ]
        }
      ],
      "source": [
        "# stats about vocabulary\n",
        "print('Unique words: ', len((vocab_to_int)))\n",
        "print()\n",
        "\n",
        "# print tokens in first review\n",
        "print('Tokenized review: \\n', reviews_ints[:1])"
      ],
      "id": "5ayX4WxDyXk_"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HUqxMWypyVo4"
      },
      "outputs": [],
      "source": [
        "# negative = 0, neutral = 1, positive = 2\n",
        "import numpy as np\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([2 if 'positive' in label else 0 if 'negative' in label else 1 for label in labels_split if label])\n"
      ],
      "id": "HUqxMWypyVo4"
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJN2EfzB3Ffs",
        "outputId": "423cdf0b-cf52-4b85-9e97-aa5bd74ea18a"
      },
      "id": "xJN2EfzB3Ffs",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, ..., 2, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpu2FeuvylOV"
      },
      "source": [
        "# Removing Outliers"
      ],
      "id": "zpu2FeuvylOV"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1idpwNPYynrs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1d3ceb-1c08-4c09-93ec-b0fbb2077c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-length reviews: 45\n",
            "Maximum review length: 5838\n"
          ]
        }
      ],
      "source": [
        "# outlier review stats\n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0])) # review_lens[0] counts the number of reviews with zero length\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "id": "1idpwNPYynrs"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FcgJ3MKSyph9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cada2608-7fd7-410f-819c-8e8a2e6b87a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews before removing outliers:  99948\n",
            "Number of reviews after removing outliers:  99903\n"
          ]
        }
      ],
      "source": [
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "# get indices of any reviews with length 0\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "id": "FcgJ3MKSyph9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PPV3IjcytNV"
      },
      "source": [
        "# Padding sequences"
      ],
      "id": "5PPV3IjcytNV"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7XMVnCppyrrn"
      },
      "outputs": [],
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's\n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "\n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "id": "7XMVnCppyrrn"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GTWWF4Chywi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104fb30a-3f0a-4626-eab5-6d249b915b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [  119    22   214   890    17     1    30  3197  3191   150]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [   11     7     4   201    18    14    89   543 14598    55]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [ 1479  7052  8185  5080   681    38     1   625     5     4]\n",
            " [    9    44   555    17     1   684  1992    21  2518    66]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]\n",
            " [    0     0     0     0     0     0     0     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "# Test your implementation!\n",
        "\n",
        "seq_length = 200\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "## test statements - do not change - ##\n",
        "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches\n",
        "print(features[:30,:10])"
      ],
      "id": "GTWWF4Chywi_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEDOQ9NYy08c"
      },
      "source": [
        "# Training, Validation, Test"
      ],
      "id": "TEDOQ9NYy08c"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-q1UnyG0yzFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000d0f7e-16eb-4c49-a8de-0d9afb26e147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(79922, 200) \n",
            "Validation set: \t(9990, 200) \n",
            "Test set: \t\t(9991, 200)\n"
          ]
        }
      ],
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "id": "-q1UnyG0yzFZ"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GIhwXpxMy4EO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure SHUFFLE your training data\n",
        "# drop_last=True will drop the last batch if the size is less than the given batch_size\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,  drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "id": "GIhwXpxMy4EO"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b5GDcDLmy7Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc43989d-d3f9-4898-aa36-614cfe4c2042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[ 462, 1396, 3294,  ..., 2685,  511,    2],\n",
            "        [ 919,    9,   78,  ...,   70,  145,    9],\n",
            "        [   0,    0,    0,  ..., 1898, 7267, 1003],\n",
            "        ...,\n",
            "        [   1,  312,   11,  ...,  381,   19, 2481],\n",
            "        [  36, 1722,    4,  ..., 1482,    1,    8],\n",
            "        [   0,    0,    0,  ...,  118,  108, 1924]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
            "        2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
            "        1, 0])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "id": "b5GDcDLmy7Wd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZUq9cIXy_b7"
      },
      "source": [
        "# Sentiment Network with PyTorch"
      ],
      "id": "jZUq9cIXy_b7"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "H-PPW-Jsy9ao"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        # Set output_size  for three classes\n",
        "        self.output_size = 3\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        #add embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # linear and ReLUx layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.ReLU = nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "\n",
        "        x = x.long()\n",
        "\n",
        "        #compute embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # ReLU function\n",
        "        ReLU_out = self.ReLU(out)\n",
        "\n",
        "        # return last ReLU output and hidden state\n",
        "        return ReLU_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden"
      ],
      "id": "H-PPW-Jsy9ao"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 4\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDIoU3Gi8wOU",
        "outputId": "14a95edc-7422-4bbc-80ad-90c20c9ee7d2"
      },
      "id": "YDIoU3Gi8wOU",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(182031, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=4, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (ReLU): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "MyGo2dGqIqCI"
      },
      "id": "MyGo2dGqIqCI"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ua9qQWGZzNEc"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "# loss and optimization functions\n",
        "lr=0.0005\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "id": "ua9qQWGZzNEc"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tRi-fmq3zt1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3ec1f1-b34c-4486-9bb3-93fec7c43f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ],
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "id": "tRi-fmq3zt1g"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "MuWC6vhC6xXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8b242a-76c8-4ffd-e89c-fa4ea6355466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3... Step: 100... Loss: 0.229507... Val Loss: 0.494144\n",
            "Epoch: 1/3... Step: 200... Loss: 0.274468... Val Loss: 0.514202\n",
            "Epoch: 1/3... Step: 300... Loss: 0.171634... Val Loss: 0.509283\n",
            "Epoch: 1/3... Step: 400... Loss: 0.330458... Val Loss: 0.508140\n",
            "Epoch: 1/3... Step: 500... Loss: 0.229334... Val Loss: 0.509444\n",
            "Epoch: 1/3... Step: 600... Loss: 0.354606... Val Loss: 0.509620\n",
            "Epoch: 1/3... Step: 700... Loss: 0.328719... Val Loss: 0.487618\n",
            "Epoch: 1/3... Step: 800... Loss: 0.346488... Val Loss: 0.503769\n",
            "Epoch: 1/3... Step: 900... Loss: 0.181998... Val Loss: 0.504937\n",
            "Epoch: 1/3... Step: 1000... Loss: 0.393922... Val Loss: 0.543446\n",
            "Epoch: 1/3... Step: 1100... Loss: 0.225744... Val Loss: 0.500255\n",
            "Epoch: 1/3... Step: 1200... Loss: 0.419885... Val Loss: 0.517257\n",
            "Epoch: 1/3... Step: 1300... Loss: 0.264943... Val Loss: 0.511308\n",
            "Epoch: 1/3... Step: 1400... Loss: 0.254726... Val Loss: 0.501522\n",
            "Epoch: 1/3... Step: 1500... Loss: 0.420228... Val Loss: 0.499182\n",
            "Epoch: 2/3... Step: 1600... Loss: 0.210351... Val Loss: 0.502267\n",
            "Epoch: 2/3... Step: 1700... Loss: 0.220696... Val Loss: 0.549072\n",
            "Epoch: 2/3... Step: 1800... Loss: 0.184688... Val Loss: 0.550366\n",
            "Epoch: 2/3... Step: 1900... Loss: 0.240063... Val Loss: 0.569746\n",
            "Epoch: 2/3... Step: 2000... Loss: 0.131573... Val Loss: 0.543351\n",
            "Epoch: 2/3... Step: 2100... Loss: 0.229504... Val Loss: 0.561861\n",
            "Epoch: 2/3... Step: 2200... Loss: 0.242251... Val Loss: 0.583777\n",
            "Epoch: 2/3... Step: 2300... Loss: 0.078885... Val Loss: 0.573413\n",
            "Epoch: 2/3... Step: 2400... Loss: 0.266772... Val Loss: 0.564924\n",
            "Epoch: 2/3... Step: 2500... Loss: 0.509423... Val Loss: 0.545798\n",
            "Epoch: 2/3... Step: 2600... Loss: 0.509432... Val Loss: 0.548766\n",
            "Epoch: 2/3... Step: 2700... Loss: 0.320555... Val Loss: 0.553335\n",
            "Epoch: 2/3... Step: 2800... Loss: 0.255538... Val Loss: 0.550221\n",
            "Epoch: 2/3... Step: 2900... Loss: 0.191239... Val Loss: 0.568565\n",
            "Epoch: 2/3... Step: 3000... Loss: 0.322923... Val Loss: 0.587273\n",
            "Epoch: 2/3... Step: 3100... Loss: 0.164865... Val Loss: 0.579561\n",
            "Epoch: 3/3... Step: 3200... Loss: 0.165292... Val Loss: 0.579508\n",
            "Epoch: 3/3... Step: 3300... Loss: 0.239897... Val Loss: 0.633354\n",
            "Epoch: 3/3... Step: 3400... Loss: 0.130119... Val Loss: 0.614212\n",
            "Epoch: 3/3... Step: 3500... Loss: 0.166916... Val Loss: 0.592438\n",
            "Epoch: 3/3... Step: 3600... Loss: 0.198098... Val Loss: 0.654702\n",
            "Epoch: 3/3... Step: 3700... Loss: 0.322312... Val Loss: 0.606877\n",
            "Epoch: 3/3... Step: 3800... Loss: 0.081936... Val Loss: 0.618607\n",
            "Epoch: 3/3... Step: 3900... Loss: 0.146924... Val Loss: 0.661379\n",
            "Epoch: 3/3... Step: 4000... Loss: 0.220055... Val Loss: 0.606056\n",
            "Epoch: 3/3... Step: 4100... Loss: 0.130413... Val Loss: 0.600612\n",
            "Epoch: 3/3... Step: 4200... Loss: 0.237363... Val Loss: 0.589688\n",
            "Epoch: 3/3... Step: 4300... Loss: 0.114179... Val Loss: 0.607771\n",
            "Epoch: 3/3... Step: 4400... Loss: 0.257152... Val Loss: 0.645281\n",
            "Epoch: 3/3... Step: 4500... Loss: 0.350872... Val Loss: 0.611130\n",
            "Epoch: 3/3... Step: 4600... Loss: 0.345522... Val Loss: 0.580523\n",
            "Epoch: 3/3... Step: 4700... Loss: 0.250088... Val Loss: 0.604496\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# training params\n",
        "epochs = 3\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip = 5  # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if train_on_gpu:\n",
        "    net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if train_on_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # 1. get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # 2. calculate the loss and perform backprop\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # 3. zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # 4. Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "\n",
        "        # 5. Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "\n",
        "            for val_inputs, val_labels in valid_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if train_on_gpu:\n",
        "                    val_inputs, val_labels = val_inputs.cuda(), val_labels.cuda()\n",
        "\n",
        "                val_output, val_h = net(val_inputs, val_h)\n",
        "                val_loss = criterion(val_output, val_labels)\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "id": "MuWC6vhC6xXR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "o9nf7sj5IxDx"
      },
      "id": "o9nf7sj5IxDx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data loss and accuracy\n",
        "#import torch.nn.functional as F\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "output, h = net(inputs, h)\n",
        "\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if train_on_gpu:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # calculate loss\n",
        "    test_loss = criterion(output, labels)\n",
        "    #labels_one_hot = F.one_hot(labels, num_classes=3)\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # get the predicted class indices (the index with the maximum probability)\n",
        "    _, pred_indices = torch.max(output, 1)\n",
        "\n",
        "    # compare predicted indices to true label\n",
        "    correct = (pred_indices == labels).sum().item()\n",
        "    num_correct += correct\n",
        "\n"
      ],
      "metadata": {
        "id": "U_7fimOHIVl8"
      },
      "id": "U_7fimOHIVl8",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "9s_DTMlcI1Nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f777ac-afbc-41b1-a8d1-6ed61daf70df"
      },
      "id": "9s_DTMlcI1Nw",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.635\n",
            "Test accuracy: 0.803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(net.state_dict(), 'model.pth')\n"
      ],
      "metadata": {
        "id": "Y1Uq6R17St9q"
      },
      "id": "Y1Uq6R17St9q",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try another one ELU and hidden 3"
      ],
      "metadata": {
        "id": "Gu3b3VkDUU_g"
      },
      "id": "Gu3b3VkDUU_g"
    },
    {
      "cell_type": "code",
      "source": [
        "#####\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        # Set output_size  for three classes\n",
        "        self.output_size = 3\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        #add embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # linear and ELU layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.ELU = nn.ELU()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "\n",
        "        x = x.long()\n",
        "\n",
        "        #compute embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out[:, -1, :] # getting the last time step output\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # ELU function\n",
        "        ELU_out = self.ELU(out)\n",
        "\n",
        "        # return last ReLU output and hidden state\n",
        "        return ELU_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "VHJP6JKPTTFC"
      },
      "id": "VHJP6JKPTTFC",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 3\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 3\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFdknGL7T5-d",
        "outputId": "73b37f3c-8828-4d9a-8723-dc2177bac843"
      },
      "id": "MFdknGL7T5-d",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(182031, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=3, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (ELU): ELU(alpha=1.0)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "# loss and optimization functions\n",
        "lr=0.0015\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "B6Lk0eWiUT8c"
      },
      "id": "B6Lk0eWiUT8c",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BnIhmJ8UmQ4",
        "outputId": "52bb8a88-9b9a-4306-8149-54954cf925b8"
      },
      "id": "1BnIhmJ8UmQ4",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# training params\n",
        "epochs = 3\n",
        "counter = 0\n",
        "print_every = 150\n",
        "clip = 5  # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if train_on_gpu:\n",
        "    net.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0015)\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if train_on_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # 1. get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # 2. calculate the loss and perform backprop\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        # 3. zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # 4. Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "\n",
        "        # 5. Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "\n",
        "            for val_inputs, val_labels in valid_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if train_on_gpu:\n",
        "                    val_inputs, val_labels = val_inputs.cuda(), val_labels.cuda()\n",
        "\n",
        "                val_output, val_h = net(val_inputs, val_h)\n",
        "                val_loss = criterion(val_output, val_labels)\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e + 1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cLu0pfhUpeq",
        "outputId": "27a43073-c307-4af4-e841-b997d2c15a4d"
      },
      "id": "4cLu0pfhUpeq",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3... Step: 150... Loss: 0.742306... Val Loss: 0.651069\n",
            "Epoch: 1/3... Step: 300... Loss: 0.675671... Val Loss: 0.630466\n",
            "Epoch: 1/3... Step: 450... Loss: 0.579329... Val Loss: 0.611579\n",
            "Epoch: 1/3... Step: 600... Loss: 0.349873... Val Loss: 0.595165\n",
            "Epoch: 1/3... Step: 750... Loss: 0.519365... Val Loss: 0.550530\n",
            "Epoch: 1/3... Step: 900... Loss: 0.512085... Val Loss: 0.537829\n",
            "Epoch: 1/3... Step: 1050... Loss: 0.418088... Val Loss: 0.536438\n",
            "Epoch: 1/3... Step: 1200... Loss: 0.496742... Val Loss: 0.520416\n",
            "Epoch: 1/3... Step: 1350... Loss: 0.445305... Val Loss: 0.505581\n",
            "Epoch: 1/3... Step: 1500... Loss: 0.464731... Val Loss: 0.502105\n",
            "Epoch: 2/3... Step: 1650... Loss: 0.368388... Val Loss: 0.532010\n",
            "Epoch: 2/3... Step: 1800... Loss: 0.422004... Val Loss: 0.509140\n",
            "Epoch: 2/3... Step: 1950... Loss: 0.493289... Val Loss: 0.505941\n",
            "Epoch: 2/3... Step: 2100... Loss: 0.319320... Val Loss: 0.481886\n",
            "Epoch: 2/3... Step: 2250... Loss: 0.425612... Val Loss: 0.475294\n",
            "Epoch: 2/3... Step: 2400... Loss: 0.307511... Val Loss: 0.468488\n",
            "Epoch: 2/3... Step: 2550... Loss: 0.452454... Val Loss: 0.487329\n",
            "Epoch: 2/3... Step: 2700... Loss: 0.439685... Val Loss: 0.463919\n",
            "Epoch: 2/3... Step: 2850... Loss: 0.436998... Val Loss: 0.483084\n",
            "Epoch: 2/3... Step: 3000... Loss: 0.428666... Val Loss: 0.462058\n",
            "Epoch: 2/3... Step: 3150... Loss: 0.342170... Val Loss: 0.461881\n",
            "Epoch: 3/3... Step: 3300... Loss: 0.202383... Val Loss: 0.482508\n",
            "Epoch: 3/3... Step: 3450... Loss: 0.338721... Val Loss: 0.489003\n",
            "Epoch: 3/3... Step: 3600... Loss: 0.375129... Val Loss: 0.492189\n",
            "Epoch: 3/3... Step: 3750... Loss: 0.182603... Val Loss: 0.498188\n",
            "Epoch: 3/3... Step: 3900... Loss: 0.326038... Val Loss: 0.505756\n",
            "Epoch: 3/3... Step: 4050... Loss: 0.376793... Val Loss: 0.489190\n",
            "Epoch: 3/3... Step: 4200... Loss: 0.367076... Val Loss: 0.472973\n",
            "Epoch: 3/3... Step: 4350... Loss: 0.209489... Val Loss: 0.469191\n",
            "Epoch: 3/3... Step: 4500... Loss: 0.437598... Val Loss: 0.469354\n",
            "Epoch: 3/3... Step: 4650... Loss: 0.182076... Val Loss: 0.470410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data loss and accuracy\n",
        "#import torch.nn.functional as F\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "output, h = net(inputs, h)\n",
        "\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if train_on_gpu:\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # calculate loss\n",
        "    test_loss = criterion(output, labels)\n",
        "    #labels_one_hot = F.one_hot(labels, num_classes=3)\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # get the predicted class indices (the index with the maximum probability)\n",
        "    _, pred_indices = torch.max(output, 1)\n",
        "\n",
        "    # compare predicted indices to true label\n",
        "    correct = (pred_indices == labels).sum().item()\n",
        "    num_correct += correct\n",
        "    # avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "id": "xMO3ytv7dPSX",
        "outputId": "d87c503d-571d-4819-f1b8-0e7aec6efe68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xMO3ytv7dPSX",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.487\n",
            "Test accuracy: 0.818\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}