{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "NXJAEKGQlTd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "qBQxl_39lkWm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ou1j5a-rjjb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69f0d4f-d5d5-48f2-8f2f-66b2c4b9e661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: False \n"
          ]
        }
      ],
      "source": [
        "### import libraries\n",
        "# download via API/Internet\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "from urllib.request import urlopen\n",
        "# data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "# data visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from matplotlib import colormaps\n",
        "# pytorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# check if GPU is available (better to check it at the start)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())\n",
        "\n",
        "# first checking if GPU is available\n",
        "# gpu_available = torch.cuda.is_available()\n",
        "\n",
        "# if(gpu_available):\n",
        "#     print('Training on GPU.')\n",
        "# else:\n",
        "#     print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### download the data from link\n",
        "# complete data (2,565,349 reviews)\n",
        "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/Video_Games.json.gz\n",
        "\n",
        "# small subset of data (497,577 reviews)\n",
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Video_Games_5.json.gz\n",
        "\n",
        "# games information\n",
        "# !wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/metaFiles2/meta_Video_Games.json.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FliHuoNXVXhw",
        "outputId": "61f0abea-3baf-499c-fd41-c75e567bc8da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-11 04:53:59--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Video_Games_5.json.gz\n",
            "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
            "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154050105 (147M) [application/x-gzip]\n",
            "Saving to: ‘Video_Games_5.json.gz’\n",
            "\n",
            "Video_Games_5.json.  61%[===========>        ]  91.09M  41.9MB/s               ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### load reviews and meta data\n",
        "# reviews\n",
        "data_rev = []\n",
        "with gzip.open('Video_Games_5.json.gz') as f:\n",
        "    for l in f:\n",
        "        data_rev.append(json.loads(l.strip()))\n",
        "\n",
        "# total length of list, this number equals total number of products\n",
        "print(len(data_rev))\n",
        "\n",
        "# first row of the list\n",
        "print(data_rev[0])\n",
        "\n",
        "# convert dictionary to dataframe\n",
        "df_rev = pd.DataFrame.from_dict(data_rev)\n",
        "\n",
        "# game data\n",
        "# data_game = []\n",
        "# with gzip.open('meta_Video_Games.json.gz') as f:\n",
        "#     for l in f:\n",
        "#         data_game.append(json.loads(l.strip()))\n",
        "\n",
        "# # total length of list, this number equals total number of products\n",
        "# print(len(data_game))\n",
        "\n",
        "# # first row of the list\n",
        "# print(data_game[0])\n",
        "\n",
        "# # convert dictionary to dataframe\n",
        "# df_game = pd.DataFrame.from_dict(data_game)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyP_uDd0VZhI",
        "outputId": "79357b73-f640-4a2a-fd20-8aaf4d9e2b7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497577\n",
            "{'overall': 5.0, 'verified': True, 'reviewTime': '10 17, 2015', 'reviewerID': 'A1HP7NVNPFMA4N', 'asin': '0700026657', 'reviewerName': 'Ambrosia075', 'reviewText': \"This game is a bit hard to get the hang of, but when you do it's great.\", 'summary': \"but when you do it's great.\", 'unixReviewTime': 1445040000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "K6Pvs0WClqgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### select relevant variables\n",
        "non_relevant_rev = [\"verified\", \"reviewTime\", \"reviewerName\", \"vote\", \"style\", \"image\", \"unixReviewTime\"]\n",
        "df_clean = df_rev.drop(non_relevant_rev, axis = 1)\n",
        "\n",
        "# non_relevant_game = [\"title\", \"feature\", \"description\", \"price\", \"imageURL\", \"related\", \"salesRank\", \"brand\", \"tech1\", \"tech2\", \"similar\"]\n",
        "# df_game = df_rev.drop(non_relevant_game, axis = 1)\n",
        "\n",
        "# fill blank spaces with NaN\n",
        "df_clean = df_clean.fillna('')\n",
        "\n",
        "# check for NaN\n",
        "df_clean.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WllY41tVcIR",
        "outputId": "2cbd3d00-734c-4750-b496-b17b10fa94f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "overall       0\n",
              "reviewerID    0\n",
              "asin          0\n",
              "reviewText    0\n",
              "summary       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing Punctuation"
      ],
      "metadata": {
        "id": "Kiuhi3F_mqo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### remove punctuations from reviews and summary\n",
        "# lower case all reviews\n",
        "df_clean[\"reviewText\"] = df_clean[\"reviewText\"].apply(lambda x: x.lower())\n",
        "\n",
        "# get rid of punctuation and newline\n",
        "df_clean[\"reviewText\"] = df_clean[\"reviewText\"].str.replace(r'[^\\w\\s]+', '', regex = True).str.replace(\"\\n\", \" \")\n",
        "\n",
        "# concatanate reviews in an array\n",
        "reviews_words = list([word for review in df_clean[\"reviewText\"].str.split() for word in review]) # numpy array consumes to much RAM"
      ],
      "metadata": {
        "id": "VjyVT-pUVdHY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Duplicates"
      ],
      "metadata": {
        "id": "e2vRz3t1mu1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### handling duplicates\n",
        "print(len(df_clean)) # with duplicates\n",
        "# get number of duplicates\n",
        "# df_dup = df_clean[df_clean.duplicated(keep = False)]\n",
        "\n",
        "# remove duplicates\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "print(len(df_clean)) # no duplicates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0FDMg-KWg1x",
        "outputId": "2f1e0373-0ba4-4dc8-c0b4-ace791392c8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "497577\n",
            "474149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format the Labels"
      ],
      "metadata": {
        "id": "q1x0oS8mm17G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### changing ratings (overall) to labels (negative = 0, neutral = 1, positive = 2)\n",
        "df_clean = df_clean.replace({\"overall\": {1: 0, 2: 0, 3: 1, 4: 2, 5: 2}}) # .map can also be used\n",
        "df_clean[\"overall\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhSa2N17nWKm",
        "outputId": "d1f0dffc-0254-4ca7-9fd9-3cf08f7c4609"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    375604\n",
              "0.0     51984\n",
              "1.0     46561\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Words & Labels"
      ],
      "metadata": {
        "id": "F8GBR0tdl1sV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # TESTING DE RAM (small subset)\n",
        "# df_clean = df_clean[:100000]\n",
        "# df_clean[\"overall\"].value_counts()\n",
        "# reviews_words = list([word for review in df_clean[\"reviewText\"].str.split() for word in review])"
      ],
      "metadata": {
        "id": "oQIkowU9uP1I"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary"
      ],
      "metadata": {
        "id": "DbueHx1VnCNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### creating the vocabulary\n",
        "counts = Counter(reviews_words) # create dictionary with frequency of appereance\n",
        "vocab = sorted(counts, key = counts.get, reverse = True) # create vocabulary ordered by frequency\n",
        "\n",
        "# map the words to integers\n",
        "vocab_to_int = {word: indx+1 for indx, word in enumerate(vocab)}\n",
        "\n",
        "# tokenize the reviews\n",
        "reviews_ints = []\n",
        "for review in df_clean[\"reviewText\"]: # remember to change the samll dataset\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
      ],
      "metadata": {
        "id": "3mc0_SkzVeXI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats about vocabulary\n",
        "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
        "print()\n",
        "\n",
        "# print tokens in first review\n",
        "print('Tokenized review: \\n', reviews_ints[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMbrghjyv424",
        "outputId": "e13c2a3e-64a0-46df-a1ac-e0586f96392b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words:  352843\n",
            "\n",
            "Tokenized review: \n",
            " [11, 10, 7, 4, 160, 169, 3, 36, 1, 1638, 5, 15, 55, 8, 59, 22, 43]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing Outliers"
      ],
      "metadata": {
        "id": "mxwqmHz-nODe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### reviews for outliers\n",
        "review_lens = Counter([len(x) for x in reviews_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0])) # review_lens[0] counts the number of reviews with zero length\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
        "\n",
        "# list of review lenghts\n",
        "review_lens = [len(x) for x in reviews_ints]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8mE9_rDfEbD",
        "outputId": "fe63ae9b-15a6-4d4d-a056-676625285cd4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-length reviews: 410\n",
            "Maximum review length: 5875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### replacing 0 length reviews with summary (still thinking to implementing or not)\n",
        "zeros = [z for z in range(len(reviews_ints)) if len(reviews_ints[z]) == 0]\n",
        "\n",
        "# for z in zeros:\n",
        "#   if len(df_clean.iloc[z, 4]) >= 3:\n",
        "#     df_clean.iloc[z, 3] = df_clean.iloc[z, 4]\n",
        "\n",
        "# using numpy array (with large datasets occupies too much RAM space)\n",
        "# lents = np.array(lents)\n",
        "# zeros = np.where(review_lens == 0)[0]\n"
      ],
      "metadata": {
        "id": "cu4irZkSpIvW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### remove outliers: any length == 0\n",
        "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
        "\n",
        "# get indices of any reviews with more than 0 length\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
        "\n",
        "# remove 0-length reviews and their labels | get the reviews with more than 0 length\n",
        "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([df_clean.iloc[ii, 0] for ii in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_ints))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvkatHQe8gej",
        "outputId": "972c7b22-47ef-446b-ca3f-9f7095df1803"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews before removing outliers:  474149\n",
            "Number of reviews after removing outliers:  473739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram of length of reviews\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.histplot(review_lens, color ='blue', bins = 50)\n",
        "plt.title('Histogram of Review Lengths')\n",
        "plt.xlabel('Number of appearances')\n",
        "plt.ylabel('Length Review')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "k2AUByZCoDA9",
        "outputId": "bb570982-56fe-4c08-b2e2-b492bbc8bf45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding / Truncating"
      ],
      "metadata": {
        "id": "yI-CTRBsmbOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### function to padd or truncate the reviews\n",
        "def pad_features(reviews_ints, seq_length):\n",
        "\n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and put it into features\n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "d_diiVh_OIry"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### padd/truncate the reviews\n",
        "# length of the reviews selected (can be changed and treated as hyperparameter)\n",
        "seq_length = 200\n",
        "\n",
        "reviews_pad = pad_features(reviews_ints, seq_length = seq_length)\n",
        "\n",
        "## test statements - do not change - ##\n",
        "assert len(reviews_pad) == len(reviews_ints), \"features should have as many rows as reviews.\"\n",
        "assert len(reviews_pad[0]) == seq_length, \"all feature rows should contain seq_length values.\""
      ],
      "metadata": {
        "id": "MsZ5_byZOToJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Validation & Testing"
      ],
      "metadata": {
        "id": "QMRd0bucniRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### split data into train, test, and validation\n",
        "reviews_train, reviews_valtest, train_labels, valtest_labels = train_test_split(reviews_pad, encoded_labels, test_size = 0.2, random_state = 69, shuffle = True)\n",
        "\n",
        "reviews_val, reviews_test, val_labels, test_labels = train_test_split(reviews_valtest, valtest_labels, test_size = 0.5, random_state = 69, shuffle = True)\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes: Percentages:\")\n",
        "print(\"Train set: \\t\\t{} \\t80%\".format(reviews_train.shape),\n",
        "      \"\\nValidation set: \\t{} \\t10%\".format(reviews_val.shape),\n",
        "      \"\\nTest set: \\t\\t{} \\t10%\".format(reviews_test.shape))"
      ],
      "metadata": {
        "id": "h9jiq-zNPHDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fb2995-7e77-4db6-d24a-0ce112831185"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes: Percentages:\n",
            "Train set: \t\t(378991, 200) \t80% \n",
            "Validation set: \t(47374, 200) \t10% \n",
            "Test set: \t\t(47374, 200) \t10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaders & Batching"
      ],
      "metadata": {
        "id": "SYTWXnnZn1TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### create Tensor datsets\n",
        "train_data = TensorDataset(torch.from_numpy(reviews_train), torch.from_numpy(train_labels))\n",
        "valid_data = TensorDataset(torch.from_numpy(reviews_val), torch.from_numpy(val_labels))\n",
        "test_data = TensorDataset(torch.from_numpy(reviews_test), torch.from_numpy(test_labels))\n",
        "\n",
        "# select batch size\n",
        "batch_size = 64 # 32/64/218\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "# drop_last=True will drop the last batch if the size is less than the given batch_size\n",
        "train_loader = DataLoader(train_data, shuffle = True, batch_size = batch_size,  drop_last = True)\n",
        "valid_loader = DataLoader(valid_data, shuffle = True, batch_size = batch_size, drop_last = True)\n",
        "test_loader = DataLoader(test_data, shuffle = True, batch_size = batch_size, drop_last = True)"
      ],
      "metadata": {
        "id": "kG7DKOt6kkAP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### testing the dataloaders\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter) # 1 batch\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjXIwQMgrdGD",
        "outputId": "569e7313-5399-409f-9082-6c96a8bf1152"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([64, 200])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,    0, 2559, 3856],\n",
            "        [   0,    0,    0,  ...,  450,  275,  132],\n",
            "        [   0,    0,    0,  ...,    5,   27,   32],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,   19,    3,  855],\n",
            "        [   0,    0,    0,  ...,    9,   22, 2730],\n",
            "        [   0,    0,    0,  ...,    0,  231,   53]])\n",
            "\n",
            "Sample label size:  torch.Size([64])\n",
            "Sample label: \n",
            " tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 0., 2., 2., 2., 2., 2., 2., 2., 0.,\n",
            "        0., 1., 2., 2., 2., 2., 1., 2., 1., 0., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
            "        2., 2., 2., 0., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
            "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "ZshUVuGKw4HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Embedding Layer"
      ],
      "metadata": {
        "id": "ntuVu_0fwiZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### custom embedding layer\n",
        "class ZeroEmbedding(nn.Embedding):\n",
        "    def reset_parameters(self):\n",
        "        self.weight.data.zero_()\n",
        "        if self.padding_idx is not None:\n",
        "            self.weight.data[self.padding_idx].fill_(0.0)"
      ],
      "metadata": {
        "id": "Zv5eYD7Du7X9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### add positional embeddings to the tokens (words)\n",
        "class PositionalEmbedding(nn.Module): # for now using the one provided, investigating an article.\n",
        "    def __init__(self, sequence_length, input_dim, output_dim):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # embedding layers to map words to vectors\n",
        "        self.token_embeddings = nn.Embedding(input_dim, output_dim)\n",
        "        # embedding layers to map position index to vectors\n",
        "        self.position_embeddings = ZeroEmbedding(sequence_length, output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        length = inputs.size(-1)\n",
        "        device = inputs.device\n",
        "        # compute positions\n",
        "        positions = torch.arange(0, self.sequence_length).unsqueeze(0).to(device)\n",
        "        # compute the word embeddings\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        # compute the positional embeddings\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        # return the final embeddings\n",
        "        return embedded_tokens + embedded_positions"
      ],
      "metadata": {
        "id": "xPB7YWSm7z-h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### hyperparameters for embedding layers\n",
        "vocab_size = len(vocab_to_int)+1  # +1 for the 0 padding\n",
        "embed_dim = 512 # dimension used in the \"Atention is all you need\""
      ],
      "metadata": {
        "id": "sLCSIWU19bUp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### define the embedding layer with positional information\n",
        "input_embed = PositionalEmbedding(seq_length, vocab_size, embed_dim)"
      ],
      "metadata": {
        "id": "r58HPw-V9cda"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### check the shape of each batch\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "sample_x.shape, sample_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdSYVi7Y9dkC",
        "outputId": "de4c0bf7-49d4-4dbe-f9d4-a5f43f203c4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 200]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### check if the positional embedding function works\n",
        "sample_emd = input_embed(sample_x)\n",
        "sample_emd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MUVV9kM9ejY",
        "outputId": "d4292579-be20-493b-ea92-639b872cb7da"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 200, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder"
      ],
      "metadata": {
        "id": "VGqyn5_pEXba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### build the transfomer\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        # multihead attention layer\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads,batch_first=True)\n",
        "\n",
        "\n",
        "        # two-layer feed-forward\n",
        "        self.dense_proj = nn.Sequential(\n",
        "            nn.Linear(embed_dim, dense_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dense_dim, embed_dim)\n",
        "        )\n",
        "        # normalization layers\n",
        "        self.layernorm_1 = nn.LayerNorm(embed_dim)\n",
        "        self.layernorm_2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        attention_output, _ = self.attention(query=inputs, key=inputs, value=inputs)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "metadata": {
        "id": "dVss05uGEWwI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model with Transformer"
      ],
      "metadata": {
        "id": "lnGYaQxhE48_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, dense_dim, sequence_length):\n",
        "        super(TransformerEncoderModel, self).__init__()\n",
        "\n",
        "        # embedding layer that maps word to vectors\n",
        "        self.embedding = PositionalEmbedding(sequence_length, vocab_size, embed_dim)\n",
        "\n",
        "        # add transformer encoder\n",
        "        self.transformer_encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(embed_dim, 3)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x,_ = torch.max(x, dim=1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return self.logsoftmax(x) # we are using NLLLoss\n"
      ],
      "metadata": {
        "id": "hiV07_ObGK3P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the initial model\n",
        "num_heads = 2 # play with this parameter\n",
        "dense_dim = 1024 # play with this parameter\n",
        "model = TransformerEncoderModel(vocab_size, embed_dim, num_heads, dense_dim, seq_length)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DdSBP4hE4xq",
        "outputId": "2fdbb69d-77a7-4bc4-ae88-75dac3241ddb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerEncoderModel(\n",
            "  (embedding): PositionalEmbedding(\n",
            "    (token_embeddings): Embedding(352844, 512)\n",
            "    (position_embeddings): ZeroEmbedding(200, 512)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (attention): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "    )\n",
            "    (dense_proj): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    )\n",
            "    (layernorm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (layernorm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (logsoftmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### check the shape of each batch and output\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "sample_output = model(sample_x)\n",
        "\n",
        "sample_x.shape, sample_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOBiwCQYIoiy",
        "outputId": "7155d2e3-3366-4b61-9dce-e83f83ccfc10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 200]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_output.size()) # batch_size\n",
        "# print('Sample label: \\n', sample_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7SBsixaURI",
        "outputId": "6dfde04d-a6db-4b33-e3df-1147e6655ba3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([64, 200])\n",
            "Sample input: \n",
            " tensor([[    20,      4,    332,  ...,   2150,     34,   1659],\n",
            "        [     0,      0,      0,  ...,     27,   1507,   1251],\n",
            "        [     0,      0,      0,  ...,      9,     22,     43],\n",
            "        ...,\n",
            "        [     0,      0,      0,  ...,   1816,      7,    252],\n",
            "        [     0,      0,      0,  ...,    806,    192,      9],\n",
            "        [   125,     89,     80,  ...,    728,     14, 248044]])\n",
            "\n",
            "Sample label size:  torch.Size([64, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Evaluation"
      ],
      "metadata": {
        "id": "QUo-yzSRstzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### move model to GPU\n",
        "model = model.to(device)\n",
        "# if(gpu_available):\n",
        "#     model.cuda()\n",
        "\n",
        "# select the criterion\n",
        "criterion = nn.NLLLoss() # NLLLoss/CrossEntropyLoss: multi-classification"
      ],
      "metadata": {
        "id": "e1fRg-7hstpW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### training function\n",
        "def training_f(model, train_loader, val_loader, num_epochs = 1, learn = 0.001, l2 = 0):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = learn, weight_decay = l2) # adam optimizer\n",
        "    max_acc = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        ### training\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs,labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # get predictions\n",
        "            outputs = model(inputs).squeeze(1)\n",
        "            # calculate loss\n",
        "            loss = criterion(outputs, labels.to(torch.int64))\n",
        "            # reset the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # backwards propagations\n",
        "            loss.backward()\n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # print training loss\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "        ### validation loop\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.inference_mode():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # get predictions\n",
        "                outputs = model(inputs).squeeze(1)\n",
        "                # compute probabilites\n",
        "                outputs_prob = torch.exp(outputs)\n",
        "                # label the prediction\n",
        "                maxlog, predicted = torch.max(outputs_prob, dim = 1, keepdim=False)\n",
        "                # add the number of labels (batch size)\n",
        "                total += labels.size(0)\n",
        "                # check if the label is correct\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                # compute the loss\n",
        "                val_loss = criterion(outputs, labels.to(torch.int64)) # just in case we want to use it\n",
        "\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        ### saving model\n",
        "        if val_acc >= max_acc:\n",
        "            max_acc = val_acc # change new valid loss min\n",
        "            print(\"Validation Accuaracy Incremented :D\")\n",
        "            torch.save(model.state_dict(), \"model_cf.pt\") # save model\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "QlUOeRFtzYGV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training benchmark model\n",
        "training_f(model, train_loader, valid_loader, num_epochs = 6, learn = 0.005, l2 = 0.001)"
      ],
      "metadata": {
        "id": "fbZdhrNWGuX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ### try new hyperparameters\n",
        "train_loader_n = DataLoader(train_data, shuffle = True, batch_size = batch_size,  drop_last = True)\n",
        "valid_loader_n = DataLoader(valid_data, shuffle = True, batch_size = batch_size, drop_last = True)\n",
        "test_loader_n = DataLoader(test_data, shuffle = True, batch_size = batch_size, drop_last = True)\n",
        "\n",
        "model_n = TransformerEncoderModel(vocab_size, embed_dim * 2, num_heads * 2, dense_dim, seq_length).to(device)\n",
        "training_f(model_n, train_loader_n, valid_loader_n, num_epochs = 6, learn = 0.001, l2 = 0.0001)"
      ],
      "metadata": {
        "id": "tgaXfAXOucPN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "8bey8BcoDPKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### testing function\n",
        "def testing_f(model, test_loader, batch_size = 64):\n",
        "  test_losses = []\n",
        "  model.eval()\n",
        "  predictions = np.zeros(len(test_loader) * batch_size)\n",
        "  all_labels = np.zeros(len(test_loader) * batch_size)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  i = 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # get predictions\n",
        "      outputs = model(inputs).squeeze(1)\n",
        "      # compute probabilites\n",
        "      outputs_prob = torch.exp(outputs)\n",
        "      # label the prediction\n",
        "      maxlog, predicted = torch.max(outputs_prob, dim = 1, keepdim=False)\n",
        "      # add the number of labels (batch size)\n",
        "      total += labels.size(0)\n",
        "      # check if the label is correct\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      # compute the loss\n",
        "      test_loss = criterion(outputs, labels.to(torch.int64))\n",
        "      # store loss\n",
        "      test_losses.append(test_loss.item())\n",
        "\n",
        "      predictions[i:i+len(labels)] = predicted.to(\"cpu\").numpy()\n",
        "      all_labels[i:i+len(labels)] = labels.to(\"cpu\").numpy()\n",
        "      i += len(labels)\n",
        "\n",
        "  print(\"Mean Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "  test_acc = 100 * correct / total\n",
        "  print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "  return predictions, all_labels"
      ],
      "metadata": {
        "id": "-p1ZqWOdDOZW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### test model\n",
        "predictions, all_labels = testing_f(model, test_loader, batch_size)"
      ],
      "metadata": {
        "id": "UqQ-YoNd5Kmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "rI7MHgX91IsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### confusion matrix function\n",
        "def conf_matrix(conf_m):\n",
        "  fig = plt.figure(figsize = (5, 5))\n",
        "  plt.imshow(conf_m, interpolation = \"nearest\", cmap = \"Blues\") # afmhot_r\n",
        "  tick_marks = np.arange(3);\n",
        "  plt.xticks(tick_marks, [\"negative\", \"neutral\", \"positive\"], rotation=90);\n",
        "  plt.yticks(tick_marks, [\"negative\", \"neutral\", \"positive\"], rotation=0);\n",
        "  plt.tight_layout();\n",
        "  thresh = conf_m.max() / 2\n",
        "  for i, j in itertools.product(range(conf_m.shape[0]), range(conf_m.shape[1])):\n",
        "        coeff = f'{conf_m[i, j]}'\n",
        "        plt.text(j, i, coeff, horizontalalignment = \"center\", verticalalignment = \"center\", color = \"white\" \\\n",
        "                 if conf_m[i, j] > thresh else \"black\")\n",
        "\n",
        "  plt.ylabel('Actual');\n",
        "  plt.xlabel('Predicted');"
      ],
      "metadata": {
        "id": "18Di9tDF1GKV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### get confusion matrix\n",
        "conf_m = confusion_matrix(all_labels, predictions)"
      ],
      "metadata": {
        "id": "Dr05JvHn5Eal"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### plot confusion matrix\n",
        "conf_matrix(conf_m)"
      ],
      "metadata": {
        "id": "vHmNWsnb5ZSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}